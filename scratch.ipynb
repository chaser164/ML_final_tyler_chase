{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo3xc-LKtfI8"
      },
      "source": [
        "# PuppyFinder: A Dog Image Classification Project\n",
        "\n",
        "*Tyler Tan & Chase Reynders*\n",
        "\n",
        "## Introduction\n",
        "\n",
        "We are using the [Stanford Dogs Dataset](https://www.kaggle.com/datasets/jessicali9530/stanford-dogs-dataset?resource=download), downloaded from Kaggle.\n",
        "\n",
        "NOTE: we should cite the things it says we should on kaggle...\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mKernel Python 3.10.0 64-bit is not usable. Check the Jupyter output tab for more information. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "!pip3 install ipython torch torchvision matplotlib pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6FA2r1ECOu2"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mKernel Python 3.10.0 64-bit is not usable. Check the Jupyter output tab for more information. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "from IPython.display import display, Image\n",
        "import os\n",
        "import statistics\n",
        "import time\n",
        "import zipfile\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import torchvision.transforms as transforms\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tempfile import TemporaryDirectory\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Workaround for downloading resnet model\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "cudnn.benchmark = True\n",
        "plt.ion()   # enables dynamic plot updating for matplotlib\n",
        "\n",
        "# Configure device (most likely cpu)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Extracting Dataset\n",
        "\n",
        "This file code chunk will only function properly if the \"archive.zip\" download from Kaggle is in the same directory as this notebook. Once the zip file is in place, this code chunk does the job of extracting its contents into a directory named `stanford_dogs`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mKernel Python 3.10.0 64-bit is not usable. Check the Jupyter output tab for more information. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "zip_file = 'archive.zip'\n",
        "dataset_dir = 'stanford_dogs'\n",
        "\n",
        "pwd = os.getcwd()\n",
        "if zip_file not in os.listdir(pwd):\n",
        "    raise FileNotFoundError(f'{zip_file} not found in {pwd}. Stopping...')\n",
        "\n",
        "\n",
        "# Create the destination folder if it doesn't exist\n",
        "if not os.path.exists(dataset_dir):\n",
        "    os.makedirs(dataset_dir)\n",
        "\n",
        "    # Unzip the file\n",
        "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "        zip_ref.extractall(dataset_dir)\n",
        "\n",
        "    print(f\"{zip_file} has been successfully extracted into {dataset_dir}.\")\n",
        "else:\n",
        "    print(f'{dataset_dir} already exists in pwd, skipping extraction.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNRc5be3Pujt"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43AgZOwfP4C8"
      },
      "source": [
        "This brief summary statistics section explores counts, averages, and other summarizing stats about this dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9UHVENjCQjj",
        "outputId": "548cfcb5-bd2b-4e59-f1dc-d7af5b4cc558"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mKernel Python 3.10.0 64-bit is not usable. Check the Jupyter output tab for more information. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "image_dir = os.path.join(dataset_dir, 'images/Images')\n",
        "files = os.listdir(image_dir)\n",
        "\n",
        "# Dictionary to store breed names and their corresponding image counts\n",
        "breed_counts = {}\n",
        "\n",
        "# Iterate through each file\n",
        "for file in files:\n",
        "    file_path = os.path.join(image_dir, file)\n",
        "    if os.path.isdir(file_path):\n",
        "        # Count the number of jpg files in the directory\n",
        "        jpg_count = sum(1 for filename in os.listdir(file_path))\n",
        "        # Store the breed name and its count in the dictionary\n",
        "        breed_counts[file] = jpg_count\n",
        "\n",
        "# Print the list of files and their corresponding image counts\n",
        "for i, (breed, count) in enumerate(breed_counts.items(), start=1):\n",
        "    print(f'{i}. {breed.split(\"-\", 1)[-1].replace(\"_\", \" \")}: ({count} images)')\n",
        "print()\n",
        "\n",
        "\n",
        "# Some more summary stats\n",
        "average = statistics.mean(breed_counts.values())\n",
        "median = statistics.median(breed_counts.values())\n",
        "std_dev = statistics.stdev(breed_counts.values())\n",
        "\n",
        "print(f'{len(breed_counts)} total breeds')\n",
        "print(f'{sum(breed_counts.values())} total images')\n",
        "print(\"Average image count for each breed:\", average)\n",
        "print(\"Median image count for each breed:\", median)\n",
        "print(\"Image count standard deviation:\", std_dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4oXnvS_EmsE"
      },
      "source": [
        "## Pre-Processing the Data\n",
        "This code utilizes the provided XML annotations from the original dataset to make a cropped-image dataset such that each image is largely of a dog."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mKernel Python 3.10.0 64-bit is not usable. Check the Jupyter output tab for more information. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "processed_dataset = 'processed_stanford_dogs'\n",
        "\n",
        "def process_dataset_objects(dataset_path, xml_dir, xml_filename, output_directory):\n",
        "    xml_file = os.path.join(dataset_path, f\"annotations/Annotation/{xml_dir}/{xml_filename}\")\n",
        "    image_file = os.path.join(dataset_path, f\"images/Images/{xml_dir}/{xml_filename}.jpg\")\n",
        "\n",
        "    # process XML file\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # Get objects and crop images\n",
        "    object_count = 0\n",
        "    for obj in root.findall(\"object\"):\n",
        "        object_count += 1\n",
        "\n",
        "        # Get bounding box coordinates\n",
        "        xmin = int(obj.find(\"bndbox/xmin\").text)\n",
        "        ymin = int(obj.find(\"bndbox/ymin\").text)\n",
        "        xmax = int(obj.find(\"bndbox/xmax\").text)\n",
        "        ymax = int(obj.find(\"bndbox/ymax\").text)\n",
        "\n",
        "        # Crop image\n",
        "        cropped_image = Image.open(image_file).crop((xmin, ymin, xmax, ymax))\n",
        "        # Ensure the cropped image is defined with RGB colorways\n",
        "        if cropped_image.mode == 'RGBA':\n",
        "            cropped_image = cropped_image.convert('RGB')\n",
        "\n",
        "        # Create output directory if it doesn't exist\n",
        "        output_subdirectory = os.path.join(output_directory, obj.find('name').text)\n",
        "        if not os.path.exists(output_subdirectory):\n",
        "            os.makedirs(output_subdirectory)\n",
        "\n",
        "        # Save cropped image\n",
        "        cropped_image_filename = os.path.join(output_subdirectory, f\"{xml_filename}_{object_count}.jpg\")\n",
        "        cropped_image.save(cropped_image_filename)\n",
        "\n",
        "    return object_count\n",
        "\n",
        "# Do nothing if path exists\n",
        "if os.path.exists(processed_dataset):\n",
        "    print(f'{processed_dataset} already exists. skipping data processing.')\n",
        "else:\n",
        "    ANNOTATION_PATH = os.path.join(dataset_dir, \"annotations/Annotation\")\n",
        "    annotation_dirs = os.listdir(ANNOTATION_PATH)\n",
        "    for annotation in annotation_dirs:\n",
        "        if annotation == '.DS_Store':\n",
        "            continue\n",
        "        BREED_PATH = os.path.join(ANNOTATION_PATH, annotation)\n",
        "        breed_annotations = os.listdir(BREED_PATH)\n",
        "        for breed_annotation in breed_annotations:\n",
        "            process_dataset_objects(dataset_path=dataset_dir, xml_dir=annotation, xml_filename=breed_annotation, output_directory=processed_dataset)\n",
        "\n",
        "    # Ensure there are 120 classes as is expected\n",
        "    assert len(os.listdir(processed_dataset)) == 120\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Making the Dataset Compatible with PyTorch\n",
        "\n",
        "In this step, we resize the images uniformly, convert them to Tensors (a matrix-like data structure), and normalize. \n",
        "\n",
        "We choose to randomly flip horizontally to introduce more variation in the training and hopefully mitigate against overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92RIHKbOEpZ8"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mKernel Python 3.10.0 64-bit is not usable. Check the Jupyter output tab for more information. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),             # Resize the images to a fixed size\n",
        "    transforms.RandomHorizontalFlip(),         # Randomly flip the image horizontally\n",
        "    transforms.ToTensor(),                     # Convert PIL Image to tensor\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "full_dataset = torchvision.datasets.ImageFolder(root=processed_dataset, transform=transform)\n",
        "\n",
        "# Define the sizes of train, validation, and test sets\n",
        "dataset_size = len(full_dataset)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "val_size = int(0.1 * dataset_size)\n",
        "test_size = dataset_size - train_size - val_size\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    full_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Define PyTorch data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define dataloaders dictionary\n",
        "dataloaders = {'train': train_loader, 'val': val_loader, 'test': test_loader}\n",
        "\n",
        "# Define dataset sizes dictionary\n",
        "dataset_sizes = {'train': train_size, 'val': val_size, 'test': test_size}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Some Sample Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mKernel Python 3.10.0 64-bit is not usable. Check the Jupyter output tab for more information. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Visualize a sample image\n",
        "sample_images, sample_labels = next(iter(train_loader))\n",
        "sample_images = sample_images.numpy()\n",
        "sample_labels = sample_labels.numpy()\n",
        "\n",
        "# Denormalize the images\n",
        "sample_images = sample_images * 0.5 + 0.5\n",
        "\n",
        "# Define classes\n",
        "class_names = full_dataset.classes\n",
        "print(class_names)\n",
        "\n",
        "# Plot the images\n",
        "fig, axes = plt.subplots(1, len(sample_images), figsize=(12, 4))\n",
        "for idx, (image, label) in enumerate(zip(sample_images, sample_labels)):\n",
        "    axes[idx].imshow(np.transpose(image, (1, 2, 0)))\n",
        "    axes[idx].set_title(class_names[label])\n",
        "    axes[idx].axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYXU5hAnH8Jt"
      },
      "source": [
        "## Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKcxXlbVH-y5",
        "outputId": "57cb3404-4c57-4fa1-c6aa-d58fe62e61a9"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mKernel Python 3.10.0 64-bit is not usable. Check the Jupyter output tab for more information. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    # Create a temporary directory to save training checkpoints\n",
        "    with TemporaryDirectory() as tempdir:\n",
        "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
        "\n",
        "        torch.save(model.state_dict(), best_model_params_path)\n",
        "        best_acc = 0.0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "            print('-' * 10)\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                # Iterate over data.\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    # zero the parameter gradients\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # forward\n",
        "                    # track history if only in train\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        # backward + optimize only if in training phase\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "                if phase == 'train':\n",
        "                    scheduler.step()\n",
        "\n",
        "                epoch_loss = running_loss / dataset_sizes[phase]\n",
        "                epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "                # deep copy the model\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "            print()\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "        print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "        # load best model weights\n",
        "        model.load_state_dict(torch.load(best_model_params_path))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuring the Convolutional Neural Network\n",
        "\n",
        "Here, we start with the resnet18 CNN from PyTorch and customize it with our tuned hyperparameters as well as an additional linear layer to ensure a 120-class output as the final layer. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mKernel Python 3.10.0 64-bit is not usable. Check the Jupyter output tab for more information. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "model_ft = models.resnet18(weights='IMAGENET1K_V1')\n",
        "\n",
        "# Define a linear fully connected layer\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 120)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.7, weight_decay=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run the Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mKernel Python 3.10.0 64-bit is not usable. Check the Jupyter output tab for more information. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Running training\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mKernel Python 3.10.0 64-bit is not usable. Check the Jupyter output tab for more information. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Save the model in the directory that contains the processed dataset\n",
        "def generate_model_filename():\n",
        "    now = datetime.now()\n",
        "    formatted_date = now.strftime(\"%y-%m-%d-%H-%M\")\n",
        "    filename = f\"model-{formatted_date}.pth\"\n",
        "    return filename\n",
        "\n",
        "# Make a \"models\" dir if it doesn't exist\n",
        "model_dir = 'models'\n",
        "if not os.path.exists(model_dir):\n",
        "    print(f'generating \"{model_dir}\" directory...')\n",
        "    os.makedirs(model_dir)\n",
        "\n",
        "curr_model_name = generate_model_filename()\n",
        "curr_model_path = os.path.join(model_dir, curr_model_name)\n",
        "\n",
        "torch.save(model_ft.state_dict(), curr_model_path)\n",
        "print(\"Model saved successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Test Accuracy\n",
        "\n",
        "This section shows the sample predictions of random images and also calculates overall accuracy with the testing partition of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mKernel Python 3.10.0 64-bit is not usable. Check the Jupyter output tab for more information. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Display image for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.5, 0.5, 0.5])\n",
        "    std = np.array([0.5, 0.5, 0.5])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "model_ft.load_state_dict(torch.load(curr_model_path))\n",
        "visualize_model(model_ft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mKernel Python 3.10.0 64-bit is not usable. Check the Jupyter output tab for more information. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Calculating percentage accuracy of testing data\n",
        "\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "# Set the model to evaluation mode and load state\n",
        "model_ft.eval()\n",
        "model_ft.load_state_dict(torch.load(curr_model_path))\n",
        "\n",
        "# Disable gradient computation for inference\n",
        "with torch.no_grad():\n",
        "    # Iterate over the test data\n",
        "    for inputs, labels in dataloaders['test']:\n",
        "        # Forward pass\n",
        "        outputs = model_ft(inputs)\n",
        "        # Get the predicted class for each sample\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        # print(f'predicted class: {predicted}')\n",
        "        # Append the predictions and ground truth labels to the lists\n",
        "        all_predictions.extend(predicted.tolist())\n",
        "        all_labels.extend(labels.tolist())\n",
        "\n",
        "# Calculate accuracy\n",
        "correct = sum(1 for pred, label in zip(all_predictions, all_labels) if pred == label)\n",
        "total = len(all_predictions)\n",
        "accuracy = correct / total\n",
        "\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "715f2d40180123dfd4771f4d0edfcc6c73529ef7d92942d3645deee6efc83151"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
